{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"small_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"AbstractAItraining.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>responses</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Cloud computing and energy consumption: Clo...</td>\n",
       "      <td>Cloud computing offers utilityoriented IT serv...</td>\n",
       "      <td>### Instruction: 1. Cloud computing and energy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. Liposomes were first described in the 1960s...</td>\n",
       "      <td>Liposomes sphereshaped vesicles consisting of ...</td>\n",
       "      <td>### Instruction: 1. Liposomes were first descr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1. Big Data Attracting Attention: The expandin...</td>\n",
       "      <td>It is already true that Big Data has drawn hug...</td>\n",
       "      <td>### Instruction: 1. Big Data Attracting Attent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1. Propensity Score: This is the probability o...</td>\n",
       "      <td>In a study comparing the effects of two treatm...</td>\n",
       "      <td>### Instruction: 1. Propensity Score: This is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. Context for Socially Interactive Robots: Th...</td>\n",
       "      <td>This paper reviews socially interactive robots...</td>\n",
       "      <td>### Instruction: 1. Context for Socially Inter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  1. Cloud computing and energy consumption: Clo...   \n",
       "1  1. Liposomes were first described in the 1960s...   \n",
       "2  1. Big Data Attracting Attention: The expandin...   \n",
       "3  1. Propensity Score: This is the probability o...   \n",
       "4  1. Context for Socially Interactive Robots: Th...   \n",
       "\n",
       "                                           responses  \\\n",
       "0  Cloud computing offers utilityoriented IT serv...   \n",
       "1  Liposomes sphereshaped vesicles consisting of ...   \n",
       "2  It is already true that Big Data has drawn hug...   \n",
       "3  In a study comparing the effects of two treatm...   \n",
       "4  This paper reviews socially interactive robots...   \n",
       "\n",
       "                                                text  \n",
       "0  ### Instruction: 1. Cloud computing and energy...  \n",
       "1  ### Instruction: 1. Liposomes were first descr...  \n",
       "2  ### Instruction: 1. Big Data Attracting Attent...  \n",
       "3  ### Instruction: 1. Propensity Score: This is ...  \n",
       "4  ### Instruction: 1. Context for Socially Inter...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"NousResearch/llama-2-7b-chat-hf\" # use this if you have access to the official LLaMA 2 model \"meta-llama/Llama-2-7b-chat-hf\", though keep in mind you'll need to pass a Hugging Face key argument\n",
    "# dataset_name = \"small_training.csv\"\n",
    "# new_model = \"llama-2-7b-custom\"\n",
    "# lora_r = 64\n",
    "# lora_alpha = 32\n",
    "# lora_dropout = 0.05\n",
    "# use_4bit = True\n",
    "# bnb_4bit_compute_dtype = \"float16\"\n",
    "# bnb_4bit_quant_type = \"nf4\"\n",
    "# use_nested_quant = False\n",
    "# output_dir = \"./results\"\n",
    "# num_train_epochs = 1\n",
    "# fp16 = False\n",
    "# bf16 = False\n",
    "# # per_device_train_batch_size = 4\n",
    "# per_device_eval_batch_size = 4\n",
    "# gradient_accumulation_steps = 1\n",
    "# gradient_checkpointing = True\n",
    "# max_grad_norm = 0.3\n",
    "# learning_rate = 2e-4\n",
    "# weight_decay = 0.001\n",
    "# optim = \"paged_adamw_32bit\"\n",
    "# lr_scheduler_type = \"constant\"\n",
    "# max_steps = -1\n",
    "# warmup_ratio = 0.03\n",
    "# group_by_length = True\n",
    "# save_steps = 25\n",
    "# logging_steps = 5\n",
    "# max_seq_length = None\n",
    "# packing = False\n",
    "# device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets from CSV\n",
    "train_dataset = load_dataset('csv', data_files='small_training.csv', split=\"train\")\n",
    "valid_dataset = load_dataset('csv', data_files='small_training.csv', split=\"train\")\n",
    "\n",
    "#Preprocess datasets\n",
    "train_dataset_mapped = train_dataset.map(lambda examples: {'text': [prompt + ' ' + response for prompt, response in zip(examples['prompt'], examples['responses'])]}, batched=True)\n",
    "valid_dataset_mapped = valid_dataset.map(lambda examples: {'text': [prompt + ' ' + response for prompt, response in zip(examples['prompt'], examples['responses'])]}, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = load_dataset('csv', data_files='small_training.csv', split=\"train\")\n",
    "#  valid_dataset = load_dataset('csv', data_files='small_training.csv', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = load_dataset('csv', data_files='AbstractAItraining.csv', split=\"train\")\n",
    "# valid_dataset = load_dataset('csv', data_files='AbstractAItraining.csv', split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'responses', 'text'],\n",
       "    num_rows: 326\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"NousResearch/llama-2-7b-chat-hf\" # use this if you have access to the official LLaMA 2 model \"meta-llama/Llama-2-7b-chat-hf\", though keep in mind you'll need to pass a Hugging Face key argument\n",
    "\n",
    "# lora_r = 64\n",
    "# lora_alpha = 32\n",
    "# lora_dropout = 0.05\n",
    "\n",
    "# output_dir = \"./results\"\n",
    "\n",
    "# per_device_train_batch_size = 4\n",
    "\n",
    "# gradient_accumulation_steps = 1\n",
    "\n",
    "# max_seq_length = None\n",
    "\n",
    "# device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype= \"float16\", \n",
    "    bnb_4bit_use_double_quant= False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:363: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:368: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"NousResearch/llama-2-7b-chat-hf\",\n",
    "    quantization_config=bnb_config,\n",
    "    load_in_4bit=True,\n",
    "    device_map={\"\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False ### \n",
    "model.config.pretraining_tp = 1 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/llama-2-7b-chat-hf\", trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapters_name = 'timdettmers/guanaco-7b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = PeftModel.from_pretrained(model , adapters_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "#model = PeftModel.from_pretrained(model , adapters_name)\n",
    "model = get_peft_model(model, peft_config=peft_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainable Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 33554432 || all params: 3533967360 || trainable%: 0.9494833591219133\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs= 1,\n",
    "    per_device_train_batch_size= 4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim= \"paged_adamw_32bit\",\n",
    "    save_steps= 25,\n",
    "    logging_steps=5,\n",
    "    warmup_ratio= 0.03,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=  0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm= 0.3,\n",
    "    max_steps= -1,\n",
    "    group_by_length= True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"all\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:166: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 326/326 [00:00<00:00, 1581.84 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Map: 100%|██████████| 326/326 [00:00<00:00, 2539.85 examples/s]\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:207: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset_mapped,\n",
    "    eval_dataset=valid_dataset_mapped,  # Pass validation dataset here\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=None,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21/82 14:29 < 46:30, 0.02 it/s, Epoch 0.24/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.026200</td>\n",
       "      <td>2.004630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>1.898936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.887900</td>\n",
       "      <td>1.830923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/41 02:21 < 01:34, 0.17 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.model.save_pretrained(new_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"[INST] Generate abstract for the key points\\n1. Chimera Design: The design of Chimera is broken into a core and extensions. The core provides basic services and visualization, while the extensions are responsible for higher level functionality, allowing third-party developers to incorporate new features according to their needs.\\n2. Multiscale Extension: The Multiscale extension of Chimera allows users to visualize large-scale molecular assemblies such as viral coats. By providing a scale-based approach, it enhances the understanding of molecular structures and interactions in biological research.\\n3. Collaboratory Extension: Offering the ability for researchers based in different locations to share a Chimera session interactively, the Collaboratory extension significantly improves collaboration capacity. Through this shared environment, researchers can conduct simultaneous examinations and share insights in real-time.\\n4. Other Extensions: Other extensions such as Multalign Viewer, ViewDock, Movie, and Volume Viewer offer a diverse set of features. They allow the display of multiple sequence alignments, screening of docked ligand orientations, replay of molecular dynamics trajectories, and analysis of volumetric data respectively.\\n5. Real-World Usage of Chimera: The abstract also discusses the practical usage of Chimera in real-world situations, pointing out its wide applicability and impact in the field of molecular biology and bioinformatics \\n . [/INST]\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=1000)\n",
    "result = pipe(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Cell 4: Test the model\n",
    "# logging.set_verbosity(logging.CRITICAL)\n",
    "# prompt = f\"[INST] Generate abstract for the key points\\n1. Chimera Design: The design of Chimera is broken into a core and extensions. The core provides basic services and visualization, while the extensions are responsible for higher level functionality, allowing third-party developers to incorporate new features according to their needs.\\n2. Multiscale Extension: The Multiscale extension of Chimera allows users to visualize large-scale molecular assemblies such as viral coats. By providing a scale-based approach, it enhances the understanding of molecular structures and interactions in biological research.\\n3. Collaboratory Extension: Offering the ability for researchers based in different locations to share a Chimera session interactively, the Collaboratory extension significantly improves collaboration capacity. Through this shared environment, researchers can conduct simultaneous examinations and share insights in real-time.\\n4. Other Extensions: Other extensions such as Multalign Viewer, ViewDock, Movie, and Volume Viewer offer a diverse set of features. They allow the display of multiple sequence alignments, screening of docked ligand orientations, replay of molecular dynamics trajectories, and analysis of volumetric data respectively.\\n5. Real-World Usage of Chimera: The abstract also discusses the practical usage of Chimera in real-world situations, pointing out its wide applicability and impact in the field of molecular biology and bioinformatics \\n . [/INST]\" # replace the command here with something relevant to your task\n",
    "\n",
    "# result = pipe(prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': '[INST] Generate abstract for the key points\\n1. Chimera Design: The design of Chimera is broken into a core and extensions. The core provides basic services and visualization, while the extensions are responsible for higher level functionality, allowing third-party developers to incorporate new features according to their needs.\\n2. Multiscale Extension: The Multiscale extension of Chimera allows users to visualize large-scale molecular assemblies such as viral coats. By providing a scale-based approach, it enhances the understanding of molecular structures and interactions in biological research.\\n3. Collaboratory Extension: Offering the ability for researchers based in different locations to share a Chimera session interactively, the Collaboratory extension significantly improves collaboration capacity. Through this shared environment, researchers can conduct simultaneous examinations and share insights in real-time.\\n4. Other Extensions: Other extensions such as Multalign Viewer, ViewDock, Movie, and Volume Viewer offer a diverse set of features. They allow the display of multiple sequence alignments, screening of docked ligand orientations, replay of molecular dynamics trajectories, and analysis of volumetric data respectively.\\n5. Real-World Usage of Chimera: The abstract also discusses the practical usage of Chimera in real-world situations, pointing out its wide applicability and impact in the field of molecular biology and bioinformatics \\n . [/INST]  The abstract of the paper \"Chimera: A Multiscale Collaboratory for Molecular Visualization\" highlights the key features and capabilities of the Chimera software. The design of Chimera is divided into a core and extensions, with the core providing basic services and visualization, while the extensions offer higher-level functionality that can be incorporated by third-party developers. The Multiscale extension of Chimera allows users to visualize large-scale molecular assemblies such as viral coats, while the Collaboratory extension enables researchers based in different locations to share a Chimera session interactively. Other extensions such as Multalign Viewer, ViewDock, Movie, and Volume Viewer offer additional features such as displaying multiple sequence alignments, screening docked ligand orientations, replaying molecular dynamics trajectories, and analyzing volumetric data. The paper also discusses the practical usage of Chimera in real-world situations, highlighting its wide applicability and impact in the field of molecular biology and bioinformatics.'}\n"
     ]
    }
   ],
   "source": [
    "# print(result[0]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
