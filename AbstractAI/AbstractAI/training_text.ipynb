{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"small_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generate abstract for the key points \\r\\nKey p...</td>\n",
       "      <td>The design implementation and capabilities of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generate abstract for the key points \\r\\nKey p...</td>\n",
       "      <td>Information technology IT acceptance research ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generate abstract for the key points \\r\\nKey p...</td>\n",
       "      <td>Motivation Phylogenies are increasingly used i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generate abstract for the key points \\r\\nKey p...</td>\n",
       "      <td>An outstanding introduction to the fundamental...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Generate abstract for the key points \\r\\nKey p...</td>\n",
       "      <td>The technology for building knowledgebased sys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Generate abstract for the key points \\r\\nKey p...   \n",
       "1  Generate abstract for the key points \\r\\nKey p...   \n",
       "2  Generate abstract for the key points \\r\\nKey p...   \n",
       "3  Generate abstract for the key points \\r\\nKey p...   \n",
       "4  Generate abstract for the key points \\r\\nKey p...   \n",
       "\n",
       "                                           responses  \n",
       "0  The design implementation and capabilities of ...  \n",
       "1  Information technology IT acceptance research ...  \n",
       "2  Motivation Phylogenies are increasingly used i...  \n",
       "3  An outstanding introduction to the fundamental...  \n",
       "4  The technology for building knowledgebased sys...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets, with 90% in the train set\n",
    "train_df = df.sample(frac=0.9, random_state=42)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "# Save the dataframes to .jsonl files\n",
    "train_df.to_json('train.jsonl', orient='records', lines=True)\n",
    "test_df.to_json('test.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"NousResearch/llama-2-7b-chat-hf\" # use this if you have access to the official LLaMA 2 model \"meta-llama/Llama-2-7b-chat-hf\", though keep in mind you'll need to pass a Hugging Face key argument\n",
    "dataset_name = \"small_training.csv\"\n",
    "new_model = \"llama-2-7b-custom\"\n",
    "lora_r = 64\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "use_4bit = True\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "use_nested_quant = False\n",
    "output_dir = \"./results\"\n",
    "num_train_epochs = 1\n",
    "fp16 = False\n",
    "bf16 = False\n",
    "per_device_train_batch_size = 4\n",
    "per_device_eval_batch_size = 4\n",
    "gradient_accumulation_steps = 1\n",
    "gradient_checkpointing = True\n",
    "max_grad_norm = 0.3\n",
    "learning_rate = 2e-4\n",
    "weight_decay = 0.001\n",
    "optim = \"paged_adamw_32bit\"\n",
    "lr_scheduler_type = \"constant\"\n",
    "max_steps = -1\n",
    "warmup_ratio = 0.03\n",
    "group_by_length = True\n",
    "save_steps = 25\n",
    "logging_steps = 5\n",
    "max_seq_length = None\n",
    "packing = False\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_csv_default-c304f0a5c531112c_0.0.0_eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d.lock'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/AbstractAI/training_text.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load datasets from CSV\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m'\u001b[39;49m\u001b[39mcsv\u001b[39;49m\u001b[39m'\u001b[39;49m, data_files\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msmall_training.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, split\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m valid_dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m'\u001b[39m\u001b[39mcsv\u001b[39m\u001b[39m'\u001b[39m, data_files\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msmall_training.csv\u001b[39m\u001b[39m'\u001b[39m, split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Preprocess datasets\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/load.py:2106\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m verification_mode \u001b[39m=\u001b[39m VerificationMode(\n\u001b[1;32m   2102\u001b[0m     (verification_mode \u001b[39mor\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mBASIC_CHECKS) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m save_infos \u001b[39melse\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2103\u001b[0m )\n\u001b[1;32m   2105\u001b[0m \u001b[39m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2106\u001b[0m builder_instance \u001b[39m=\u001b[39m load_dataset_builder(\n\u001b[1;32m   2107\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m   2108\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2109\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   2110\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   2111\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2112\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   2113\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   2114\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   2115\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2116\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   2117\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2118\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig_kwargs,\n\u001b[1;32m   2119\u001b[0m )\n\u001b[1;32m   2121\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2122\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/load.py:1829\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1827\u001b[0m builder_cls \u001b[39m=\u001b[39m get_dataset_builder_class(dataset_module, dataset_name\u001b[39m=\u001b[39mdataset_name)\n\u001b[1;32m   1828\u001b[0m \u001b[39m# Instantiate the dataset builder\u001b[39;00m\n\u001b[0;32m-> 1829\u001b[0m builder_instance: DatasetBuilder \u001b[39m=\u001b[39m builder_cls(\n\u001b[1;32m   1830\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1831\u001b[0m     dataset_name\u001b[39m=\u001b[39;49mdataset_name,\n\u001b[1;32m   1832\u001b[0m     config_name\u001b[39m=\u001b[39;49mconfig_name,\n\u001b[1;32m   1833\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1834\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1835\u001b[0m     \u001b[39mhash\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mhash\u001b[39;49m,\n\u001b[1;32m   1836\u001b[0m     info\u001b[39m=\u001b[39;49minfo,\n\u001b[1;32m   1837\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   1838\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1839\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   1840\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbuilder_kwargs,\n\u001b[1;32m   1841\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig_kwargs,\n\u001b[1;32m   1842\u001b[0m )\n\u001b[1;32m   1844\u001b[0m \u001b[39mreturn\u001b[39;00m builder_instance\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/builder.py:415\u001b[0m, in \u001b[0;36mDatasetBuilder.__init__\u001b[0;34m(self, cache_dir, dataset_name, config_name, hash, base_path, info, features, token, use_auth_token, repo_id, data_files, data_dir, storage_options, writer_batch_size, name, **config_kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m os\u001b[39m.\u001b[39mmakedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_dir_root, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    414\u001b[0m lock_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_dir_root, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_dir\u001b[39m.\u001b[39mreplace(os\u001b[39m.\u001b[39msep, \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.lock\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 415\u001b[0m \u001b[39mwith\u001b[39;00m FileLock(lock_path):\n\u001b[1;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_dir):  \u001b[39m# check if data exist\u001b[39;00m\n\u001b[1;32m    417\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(os\u001b[39m.\u001b[39mlistdir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_dir)) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/filelock.py:320\u001b[0m, in \u001b[0;36mBaseFileLock.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 320\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/filelock.py:270\u001b[0m, in \u001b[0;36mBaseFileLock.acquire\u001b[0;34m(self, timeout, poll_intervall)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_locked:\n\u001b[1;32m    269\u001b[0m         logger()\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttempting to acquire lock \u001b[39m\u001b[39m{\u001b[39;00mlock_id\u001b[39m}\u001b[39;00m\u001b[39m on \u001b[39m\u001b[39m{\u001b[39;00mlock_filename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_acquire()\n\u001b[1;32m    272\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_locked:\n\u001b[1;32m    273\u001b[0m     logger()\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLock \u001b[39m\u001b[39m{\u001b[39;00mlock_id\u001b[39m}\u001b[39;00m\u001b[39m acquired on \u001b[39m\u001b[39m{\u001b[39;00mlock_filename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/filelock.py:404\u001b[0m, in \u001b[0;36mUnixFileLock._acquire\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_acquire\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    403\u001b[0m     open_mode \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mO_RDWR \u001b[39m|\u001b[39m os\u001b[39m.\u001b[39mO_CREAT \u001b[39m|\u001b[39m os\u001b[39m.\u001b[39mO_TRUNC\n\u001b[0;32m--> 404\u001b[0m     fd \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lock_file, open_mode)\n\u001b[1;32m    406\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m         fcntl\u001b[39m.\u001b[39mflock(fd, fcntl\u001b[39m.\u001b[39mLOCK_EX \u001b[39m|\u001b[39m fcntl\u001b[39m.\u001b[39mLOCK_NB)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_csv_default-c304f0a5c531112c_0.0.0_eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d.lock'"
     ]
    }
   ],
   "source": [
    "# Load datasets from CSV\n",
    "train_dataset = load_dataset('csv', data_files='small_training.csv', split=\"train\")\n",
    "valid_dataset = load_dataset('csv', data_files='small_training.csv', split=\"train\")\n",
    "\n",
    "# Preprocess datasets\n",
    "train_dataset_mapped = train_dataset.map(lambda examples: {'text': [prompt + ' ' + response for prompt, response in zip(examples['prompt'], examples['responses'])]}, batched=True)\n",
    "valid_dataset_mapped = valid_dataset.map(lambda examples: {'text': [prompt + ' ' + response for prompt, response in zip(examples['prompt'], examples['responses'])]}, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5859cfa52ba2435ca3ad6d3a912facae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3c14652fbf4dd6b62f3b9a67850da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/29.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1338a9d2bacd498fbd9a940beeabebe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0781fa4c9f343f2bfffad8e48bd55a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00005.bin:   0%|          | 0.00/9.82G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/.cache/huggingface/hub/models--chargoddard--llama2-22b-blocktriangular/tmp_d4202e82-c990-43c8-a56c-b4d6b1bc4a74'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1650\u001b[0m, in \u001b[0;36m_chmod_and_replace\u001b[0;34m(src, dst)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1650\u001b[0m     tmp_file\u001b[39m.\u001b[39;49mtouch()\n\u001b[1;32m   1651\u001b[0m     cache_dir_mode \u001b[39m=\u001b[39m Path(tmp_file)\u001b[39m.\u001b[39mstat()\u001b[39m.\u001b[39mst_mode\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/pathlib.py:1168\u001b[0m, in \u001b[0;36mPath.touch\u001b[0;34m(self, mode, exist_ok)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[39mCreate this file with the given access mode, if it doesn't exist.\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1168\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mtouch(\u001b[39mself\u001b[39;49m, mode, exist_ok)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/pathlib.py:331\u001b[0m, in \u001b[0;36m_NormalAccessor.touch\u001b[0;34m(self, path, mode, exist_ok)\u001b[0m\n\u001b[1;32m    330\u001b[0m     flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mO_EXCL\n\u001b[0;32m--> 331\u001b[0m fd \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mopen(path, flags, mode)\n\u001b[1;32m    332\u001b[0m os\u001b[39m.\u001b[39mclose(fd)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/root/.cache/huggingface/hub/models--chargoddard--llama2-22b-blocktriangular/tmp_d4202e82-c990-43c8-a56c-b4d6b1bc4a74'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/AbstractAI/training_text.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m compute_dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(torch, bnb_4bit_compute_dtype)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m bnb_config \u001b[39m=\u001b[39m BitsAndBytesConfig(\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     load_in_4bit\u001b[39m=\u001b[39muse_4bit,\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     bnb_4bit_quant_type\u001b[39m=\u001b[39mbnb_4bit_quant_type,\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     bnb_4bit_compute_dtype\u001b[39m=\u001b[39mcompute_dtype,\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     bnb_4bit_use_double_quant\u001b[39m=\u001b[39muse_nested_quant,\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     model_name,\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     quantization_config\u001b[39m=\u001b[39;49mbnb_config,\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     device_map\u001b[39m=\u001b[39;49mdevice_map\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_cache \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a22643a5c5c726d65656e615c5c41627374726163744149222c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a22643a5c5c726d65656e615c5c416273747261637441495c5c2e646576636f6e7461696e65725c5c646576636f6e7461696e65722e6a736f6e222c225f736570223a312c2265787465726e616c223a2266696c653a2f2f2f642533412f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f643a2f726d65656e612f416273747261637441492f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/AbstractAI/training_text.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpretraining_tp \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:493\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    492\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    494\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    495\u001b[0m     )\n\u001b[1;32m    496\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    497\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2610\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2607\u001b[0m \u001b[39m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[1;32m   2608\u001b[0m \u001b[39mif\u001b[39;00m is_sharded:\n\u001b[1;32m   2609\u001b[0m     \u001b[39m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[0;32m-> 2610\u001b[0m     resolved_archive_file, sharded_metadata \u001b[39m=\u001b[39m get_checkpoint_shard_files(\n\u001b[1;32m   2611\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   2612\u001b[0m         resolved_archive_file,\n\u001b[1;32m   2613\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2614\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   2615\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   2616\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   2617\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   2618\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   2619\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   2620\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2621\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   2622\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m   2623\u001b[0m     )\n\u001b[1;32m   2625\u001b[0m \u001b[39m# load pt weights early so that we know which dtype to init the model under\u001b[39;00m\n\u001b[1;32m   2626\u001b[0m \u001b[39mif\u001b[39;00m from_pt:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:958\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, use_auth_token, user_agent, revision, subfolder, _commit_hash)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[39mfor\u001b[39;00m shard_filename \u001b[39min\u001b[39;00m tqdm(shard_filenames, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading shards\u001b[39m\u001b[39m\"\u001b[39m, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m    956\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m         \u001b[39m# Load from URL\u001b[39;00m\n\u001b[0;32m--> 958\u001b[0m         cached_filename \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    959\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m    960\u001b[0m             shard_filename,\n\u001b[1;32m    961\u001b[0m             cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    962\u001b[0m             force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    963\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    964\u001b[0m             resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    965\u001b[0m             local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    966\u001b[0m             use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    967\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    968\u001b[0m             revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    969\u001b[0m             subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    970\u001b[0m             _commit_hash\u001b[39m=\u001b[39;49m_commit_hash,\n\u001b[1;32m    971\u001b[0m         )\n\u001b[1;32m    972\u001b[0m     \u001b[39m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[1;32m    973\u001b[0m     \u001b[39m# we don't have to catch them here.\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[39mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    414\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    418\u001b[0m         path_or_repo_id,\n\u001b[1;32m    419\u001b[0m         filename,\n\u001b[1;32m    420\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    421\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    422\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    423\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    424\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    425\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    426\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    427\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    428\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    429\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    430\u001b[0m     )\n\u001b[1;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m    433\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    434\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1442\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1441\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mblob_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1442\u001b[0m     _chmod_and_replace(temp_file\u001b[39m.\u001b[39;49mname, blob_path)\n\u001b[1;32m   1443\u001b[0m     _create_symlink(blob_path, pointer_path, new_blob\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1444\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1654\u001b[0m, in \u001b[0;36m_chmod_and_replace\u001b[0;34m(src, dst)\u001b[0m\n\u001b[1;32m   1652\u001b[0m     os\u001b[39m.\u001b[39mchmod(src, stat\u001b[39m.\u001b[39mS_IMODE(cache_dir_mode))\n\u001b[1;32m   1653\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m-> 1654\u001b[0m     tmp_file\u001b[39m.\u001b[39;49munlink()\n\u001b[1;32m   1656\u001b[0m shutil\u001b[39m.\u001b[39mmove(src, dst)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/pathlib.py:1206\u001b[0m, in \u001b[0;36mPath.unlink\u001b[0;34m(self, missing_ok)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[39mRemove this file or link.\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[39mIf the path is a directory, use rmdir() instead.\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1206\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49munlink(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   1207\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m   1208\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_ok:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/.cache/huggingface/hub/models--chargoddard--llama2-22b-blocktriangular/tmp_d4202e82-c990-43c8-a56c-b4d6b1bc4a74'"
     ]
    }
   ],
   "source": [
    "#\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"all\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5  # Evaluate every 20 steps\n",
    ")\n",
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset_mapped,\n",
    "    eval_dataset=valid_dataset_mapped,  # Pass validation dataset here\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")\n",
    "trainer.train()\n",
    "trainer.model.save_pretrained(new_model) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 4: Test the model\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "prompt = f\"[INST] Generate abstract for the key points\\n1. Chimera Design: The design of Chimera is broken into a core and extensions. The core provides basic services and visualization, while the extensions are responsible for higher level functionality, allowing third-party developers to incorporate new features according to their needs.\\n2. Multiscale Extension: The Multiscale extension of Chimera allows users to visualize large-scale molecular assemblies such as viral coats. By providing a scale-based approach, it enhances the understanding of molecular structures and interactions in biological research.\\n3. Collaboratory Extension: Offering the ability for researchers based in different locations to share a Chimera session interactively, the Collaboratory extension significantly improves collaboration capacity. Through this shared environment, researchers can conduct simultaneous examinations and share insights in real-time.\\n4. Other Extensions: Other extensions such as Multalign Viewer, ViewDock, Movie, and Volume Viewer offer a diverse set of features. They allow the display of multiple sequence alignments, screening of docked ligand orientations, replay of molecular dynamics trajectories, and analysis of volumetric data respectively.\\n5. Real-World Usage of Chimera: The abstract also discusses the practical usage of Chimera in real-world situations, pointing out its wide applicability and impact in the field of molecular biology and bioinformatics \\n . [/INST]\" # replace the command here with something relevant to your task\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=1000)\n",
    "result = pipe(prompt) \n",
    "print(result[0]['generated_text']) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
